{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 225 layers, 3157200 parameters, 0 gradients, 8.9 GFLOPs\n",
      "-----\n",
      "YOLOv8n-mini14-det summary: 213 layers, 1123368 parameters, 0 gradients, 3.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(213, 1123368, 0, 3.896832)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model1 = YOLO(\"yolov8n.pt\")\n",
    "model2 = YOLO(\"yolov8n-mini.pt\")\n",
    "\n",
    "model1.info(verbose=True)\n",
    "print(\"-----\")\n",
    "model2.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed98961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /media/data/Mironshoh/projects/segmentation-experiments/sample_coco_train_000000273841.jpg: 640x480 3 persons, 3 bottles, 4.1ms\n",
      "Speed: 25.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /media/data/Mironshoh/projects/segmentation-experiments/sample_coco_train_000000273841.jpg: 640x480 3 persons, 3 bottles, 3.8ms\n",
      "Speed: 0.6ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Inference Time: 8.54 ms\n",
      "\n",
      "image 1/1 /media/data/Mironshoh/projects/segmentation-experiments/sample_coco_train_000000273841.jpg: 640x480 4 persons, 1 bottle, 3.4ms\n",
      "Speed: 0.7ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /media/data/Mironshoh/projects/segmentation-experiments/sample_coco_train_000000273841.jpg: 640x480 4 persons, 1 bottle, 3.4ms\n",
      "Speed: 1.0ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Inference Time: 8.42 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[125, 150, 176],\n",
       "         [130, 155, 181],\n",
       "         [130, 155, 181],\n",
       "         ...,\n",
       "         [ 38,  92, 216],\n",
       "         [ 41,  94, 221],\n",
       "         [ 35,  88, 215]],\n",
       " \n",
       "        [[124, 149, 175],\n",
       "         [128, 153, 179],\n",
       "         [129, 154, 180],\n",
       "         ...,\n",
       "         [ 48,  96, 198],\n",
       "         [ 39,  92, 209],\n",
       "         [ 40,  94, 219]],\n",
       " \n",
       "        [[122, 149, 175],\n",
       "         [124, 151, 177],\n",
       "         [128, 153, 179],\n",
       "         ...,\n",
       "         [  0,   1,  57],\n",
       "         [ 52, 100, 202],\n",
       "         [ 38,  92, 216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  24,  71],\n",
       "         [ 16,  27,  71],\n",
       "         [ 17,  28,  72],\n",
       "         ...,\n",
       "         [ 28,  63, 119],\n",
       "         [ 28,  61, 117],\n",
       "         [ 31,  61, 118]],\n",
       " \n",
       "        [[ 32,  42,  90],\n",
       "         [ 24,  34,  81],\n",
       "         [ 17,  27,  74],\n",
       "         ...,\n",
       "         [ 33,  67, 126],\n",
       "         [ 30,  62, 121],\n",
       "         [ 35,  65, 124]],\n",
       " \n",
       "        [[ 74,  84, 132],\n",
       "         [ 54,  64, 112],\n",
       "         [ 32,  42,  89],\n",
       "         ...,\n",
       "         [ 32,  66, 126],\n",
       "         [ 28,  59, 120],\n",
       "         [ 33,  62, 123]]], dtype=uint8)\n",
       " orig_shape: (640, 480)\n",
       " path: '/media/data/Mironshoh/projects/segmentation-experiments/sample_coco_train_000000273841.jpg'\n",
       " probs: None\n",
       " save_dir: '/home/humblebee/code/QC/hb-yolo/runs/detect/predict'\n",
       " speed: {'preprocess': 1.0023117065429688, 'inference': 3.381490707397461, 'postprocess': 0.6971359252929688}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Example image for inference (can be an image file, here using a random numpy array)\n",
    "image_path = 'sample_coco_train_000000273841.jpg'  # Replace with your actual image path\n",
    "\n",
    "results = model1(image_path)  # Inference\n",
    "# Time inference process\n",
    "start_time = time.time()  # Start the timer\n",
    "results = model1(image_path)  # Inference\n",
    "end_time = time.time()  # End the timer\n",
    "inference_time_ms = (end_time - start_time) * 1000  # Convert to ms\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "results = model2(image_path)  # Inference\n",
    "start_time = time.time()  # Start the timer\n",
    "results = model2(image_path)  # Inference\n",
    "end_time = time.time()  # End the timer\n",
    "# Calculate processing time in milliseconds\n",
    "inference_time_ms = (end_time - start_time) * 1000  # Convert to ms\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Optionally, print out results (e.g., detections)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: /media/data/Mironshoh/projects/segmentation-experiments/tr_light_data\n",
      "Destination merged dataset: /media/data/Mironshoh/projects/segmentation-experiments/tr_light_data/final_train_data_3\n",
      "\n",
      "=== Merging dataset: hw3-1-2 ===\n",
      "  Split train -> train: 20 images\n",
      "  Split valid -> val: 10 images\n",
      "  Split test -> test: 5 images\n",
      "\n",
      "=== Merging dataset: hw3-1-3 ===\n",
      "  Split train -> train: 20 images\n",
      "  Split valid -> val: 10 images\n",
      "  Split test -> test: 5 images\n",
      "\n",
      "=== Merging dataset: light-4 ===\n",
      "  Split train -> train: 32 images\n",
      "  Split valid -> val: 9 images\n",
      "  Split test -> test: 5 images\n",
      "\n",
      "=== Merging dataset: Traffic-Light-1 ===\n",
      "  Split train -> train: 35 images\n",
      "  Split valid -> val: 9 images\n",
      "  Split test -> test: 6 images\n",
      "\n",
      "=== Merging dataset: traffic-signs-3 ===\n",
      "  Split train -> train: 3245 images\n",
      "  Split valid -> val: 758 images\n",
      "  Split test -> test: 614 images\n",
      "\n",
      "=== Merging dataset: traffic-lights-v1 ===\n",
      "  Split train -> train: 204 images\n",
      "  Split valid -> val: 20 images\n",
      "  Split test -> test: 13 images\n",
      "\n",
      "=== Merging dataset: traffic-1 ===\n",
      "  Split train -> train: 81 images\n",
      "\n",
      "=== Merging dataset: traffic-2 ===\n",
      "  Split train -> train: 81 images\n",
      "\n",
      "=== Merging dataset: traffic-3 ===\n",
      "  Split train -> train: 81 images\n",
      "\n",
      "=== Merging dataset: traffic-4 ===\n",
      "  Split train -> train: 81 images\n",
      "\n",
      "=== Merging dataset: traffic-light-1 ===\n",
      "  Split train -> train: 338 images\n",
      "  Split valid -> val: 100 images\n",
      "  Split test -> test: 49 images\n",
      "\n",
      "=== Merging dataset: Traffic-light-red-1 ===\n",
      "  Split train -> train: 200 images\n",
      "\n",
      "=== Merging dataset: traffic-lights-v1 ===\n",
      "  Split train -> train: 204 images\n",
      "  Split valid -> val: 20 images\n",
      "  Split test -> test: 13 images\n",
      "\n",
      "=== Merging dataset: Traffic-light-green-1 ===\n",
      "  Split train -> train: 200 images\n",
      "\n",
      "=== Merging dataset: Green-light-1 ===\n",
      "  Split train -> train: 210 images\n",
      "  Split valid -> val: 30 images\n",
      "\n",
      "Done! Merged dataset created at: /media/data/Mironshoh/projects/segmentation-experiments/tr_light_data/final_train_data_3\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Root of all your datasets\n",
    "ROOT = Path(\"/media/data/Mironshoh/projects/segmentation-experiments/tr_light_data\")\n",
    "\n",
    "# Destination merged dataset (NEW, not in-place)\n",
    "DEST = ROOT / \"final_train_data_3\"\n",
    "\n",
    "FINAL_NAMES = [\n",
    "    \"green traffic\",   # 1\n",
    "    \"red traffic\",     # 2\n",
    "    \"yellow traffic\",  # 3\n",
    "    \"Bump\",            # 4\n",
    "    \"No_Parking\",      # 5\n",
    "    \"No_Stopping\",     # 6\n",
    "    \"No_U-Turn\",       # 7\n",
    "    \"Pedestrian_sign\", # 8\n",
    "    \"Road_Work\",       # 9\n",
    "    \"Speed_Limit_120\",  # 10\n",
    "    \"Speed_Limit_40\",   # 11\n",
    "    \"Speed_Limit_90\",   # 12\n",
    "]\n",
    "\n",
    "# Dataset-specific class mappings: old_index -> new_index\n",
    "MAPPINGS = {\n",
    "    \"hw3-1-2\": {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "    },\n",
    "    \n",
    "    \"hw3-1-3\": {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "    },\n",
    "\n",
    "    # light-4: names [Greed, Green, Red, Unknown]\n",
    "    \"light-4\": {\n",
    "        0: 0,  # Greed   -> Traffic Green (assumed typo)\n",
    "        1: 0,  # Green   -> Traffic Green\n",
    "        2: 1,  # Red     -> Traffic Red\n",
    "    },\n",
    "\n",
    "    # Traffic-Light-1: names [Traffic Light -Green-, -Red-, -Yellow-]\n",
    "    \"Traffic-Light-1\": {\n",
    "        0: 0,  # -> Traffic Green\n",
    "        1: 1,  # -> Traffic Red\n",
    "        # 2: 3,  # -> Traffic Yellow\n",
    "    },\n",
    "\n",
    "    # traffic-signs-3: names [Bump, No_Parking, No_Stopping, No_U-Turn, Pedestrian, Road_Work, Speed_Limit_120, Speed_Limit_40, Speed_Limit_90, Stop]\n",
    "    \"traffic-signs-3\": {\n",
    "        0: 2,   # Bump\n",
    "        1: 3,   # No_Parking\n",
    "        2: 4,   # No_Stopping\n",
    "        3: 5,   # No_U-Turn\n",
    "        4: 6,   # Pedestrian\n",
    "        5: 7,  # Road_Work\n",
    "        6: 8,  # Speed_Limit_120\n",
    "        7: 9,  # Speed_Limit_40\n",
    "        8: 10,  # Speed_Limit_90\n",
    "    },\n",
    "    \n",
    "    \"traffic-lights-v1\": {\n",
    "        0: 1,\n",
    "        # 1: 3,\n",
    "        2: 0,\n",
    "    },\n",
    "    \n",
    "    \"traffic-1\": {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        # 2: 3,\n",
    "    },\n",
    "    \n",
    "    \"traffic-2\": {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        # 2: 3,\n",
    "    },\n",
    "    \n",
    "    \"traffic-3\": {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        # 2: 3,\n",
    "    },\n",
    "    \n",
    "    \"traffic-4\": {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        # 2: 3,\n",
    "    },\n",
    "    \n",
    "    \"traffic-light-1\": {\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        # 5: 3,\n",
    "    },\n",
    "    \n",
    "    \"Traffic-light-red-1\": {\n",
    "        0: 1,\n",
    "    },\n",
    "    \n",
    "    \"traffic-lights-v1\": {\n",
    "        0: 1,\n",
    "        # 1: 3,\n",
    "        2: 0,\n",
    "    },\n",
    "    \n",
    "    \"Traffic-light-green-1\": {\n",
    "        0: 0,\n",
    "    },\n",
    "    \n",
    "    \"Green-light-1\": {\n",
    "        0: 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "# List of datasets to merge\n",
    "SOURCE_DATASETS = [\n",
    "    \"hw3-1-2\",\n",
    "    \"hw3-1-3\",\n",
    "    \"light-4\",\n",
    "    \"Traffic-Light-1\",\n",
    "    \"traffic-signs-3\",\n",
    "    # \"traffic-lights-1\",\n",
    "    \"traffic-lights-v1\",\n",
    "    \"traffic-1\",\n",
    "    \"traffic-2\",\n",
    "    \"traffic-3\",\n",
    "    \"traffic-4\",\n",
    "    \"traffic-light-1\",\n",
    "    \"Traffic-light-red-1\",\n",
    "    \"traffic-lights-v1\",\n",
    "    \"Traffic-light-green-1\",\n",
    "    \"Green-light-1\",\n",
    "]\n",
    "\n",
    "# Possible source splits. \"valid\" will be mapped to \"val\" in destination.\n",
    "SRC_SPLITS = [\"train\", \"val\", \"valid\", \"test\"]\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "\n",
    "def ensure_dir(path: Path):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def remap_and_copy_label(src_lbl: Path, dst_lbl: Path, mapping: dict | None):\n",
    "    \"\"\"Read src_lbl, remap class indices using mapping, write dst_lbl.\"\"\"\n",
    "    if mapping is None:\n",
    "        # No mapping means copy as-is (should not happen here, but safe)\n",
    "        if src_lbl.exists():\n",
    "            shutil.copy2(src_lbl, dst_lbl)\n",
    "        else:\n",
    "            dst_lbl.touch()\n",
    "        return\n",
    "\n",
    "    if not src_lbl.exists():\n",
    "        # No label file -> create empty (image with no objects)\n",
    "        dst_lbl.touch()\n",
    "        return\n",
    "\n",
    "    lines_out = []\n",
    "    with src_lbl.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            try:\n",
    "                old_cls = int(parts[0])\n",
    "            except ValueError:\n",
    "                continue  # skip malformed line\n",
    "\n",
    "            if old_cls not in mapping:\n",
    "                # Class not in mapping -> drop this object\n",
    "                continue\n",
    "\n",
    "            new_cls = mapping[old_cls]\n",
    "            parts[0] = str(new_cls)\n",
    "            lines_out.append(\" \".join(parts))\n",
    "\n",
    "    with dst_lbl.open(\"w\") as f:\n",
    "        for ln in lines_out:\n",
    "            f.write(ln + \"\\n\")\n",
    "\n",
    "\n",
    "def merge_one_dataset(dname: str):\n",
    "    print(f\"\\n=== Merging dataset: {dname} ===\")\n",
    "    ds_root = ROOT / dname\n",
    "    if not ds_root.exists():\n",
    "        print(f\"[WARN] Dataset folder not found: {ds_root}\")\n",
    "        return\n",
    "\n",
    "    mapping = MAPPINGS.get(dname, None)\n",
    "    if mapping is None:\n",
    "        print(f\"[INFO] No mapping found for {dname}, labels will be copied as-is.\")\n",
    "\n",
    "    for src_split in SRC_SPLITS:\n",
    "        src_img_dir = ds_root / src_split / \"images\"\n",
    "        src_lbl_dir = ds_root / src_split / \"labels\"\n",
    "\n",
    "        if not src_img_dir.exists():\n",
    "            continue\n",
    "\n",
    "        # Destination split: normalize \"valid\" -> \"val\"\n",
    "        if src_split == \"valid\":\n",
    "            split = \"val\"\n",
    "        else:\n",
    "            split = src_split\n",
    "\n",
    "        dst_img_dir = DEST / split / \"images\"\n",
    "        dst_lbl_dir = DEST / split / \"labels\"\n",
    "        ensure_dir(dst_img_dir)\n",
    "        ensure_dir(dst_lbl_dir)\n",
    "\n",
    "        img_files = [\n",
    "            p for p in src_img_dir.rglob(\"*\")\n",
    "            if p.is_file() and p.suffix.lower() in IMG_EXTS\n",
    "        ]\n",
    "\n",
    "        print(f\"  Split {src_split} -> {split}: {len(img_files)} images\")\n",
    "\n",
    "        for img_path in img_files:\n",
    "            stem = img_path.stem\n",
    "            ext = img_path.suffix.lower()\n",
    "            src_lbl_path = src_lbl_dir / f\"{stem}.txt\"\n",
    "\n",
    "            # Unique name to avoid collisions\n",
    "            new_stem = f\"{dname}_{split}_{stem}\"\n",
    "            dst_img_path = dst_img_dir / f\"{new_stem}{ext}\"\n",
    "            dst_lbl_path = dst_lbl_dir / f\"{new_stem}.txt\"\n",
    "\n",
    "            # Copy image\n",
    "            shutil.copy2(img_path, dst_img_path)\n",
    "\n",
    "            # Remap and copy label\n",
    "            remap_and_copy_label(src_lbl_path, dst_lbl_path, mapping)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Root: {ROOT}\")\n",
    "    print(f\"Destination merged dataset: {DEST}\")\n",
    "    for dname in SOURCE_DATASETS:\n",
    "        merge_one_dataset(dname)\n",
    "    print(\"\\nDone! Merged dataset created at:\", DEST)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
